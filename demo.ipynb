{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from load_glove_matrix import Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained Glove vectors from file ./data/glove.840B.300d.txt\n",
      "  --9.11%  loaded.\n",
      "  --18.21%  loaded.\n",
      "  --27.32%  loaded.\n",
      "  --36.43%  loaded.\n",
      "  --45.54%  loaded.\n",
      "  --54.64%  loaded.\n",
      "  --63.75%  loaded.\n",
      "  --72.86%  loaded.\n",
      "  --81.97%  loaded.\n",
      "  --91.07%  loaded.\n",
      "Finished loading Glove model. 2196017 vectors loaded\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained Glove vectors, 300d\n",
    "glove_model = Glove()\n",
    "glove_model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unique words and part of speach\n",
    "def find_words_pos(words, tags):\n",
    "    uniqueWords = [] \n",
    "    posWords = []\n",
    "    for i in words:\n",
    "        if not i in uniqueWords:\n",
    "            uniqueWords.append(i)\n",
    "    for tag in tags:\n",
    "        for word in uniqueWords:\n",
    "            if word[1] == tag:\n",
    "                posWords.append(word)\n",
    "            else:\n",
    "                continue\n",
    "    return posWords\n",
    "\n",
    "def find_words(words, trigger):\n",
    "    l = []\n",
    "    for word in words:\n",
    "        if trigger not in ('word', 'pos'):\n",
    "            print(\"Invalid trigger should be 'word' or 'pos'\")\n",
    "            break\n",
    "        elif trigger == 'word':\n",
    "            l.append(word[0])\n",
    "        elif trigger == 'pos':\n",
    "            l.append(word[1])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing words...\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n",
      "<root><document><sentences><sentence id=\"1\" sentimentValue=\"3\" sentiment=\"Positive\"><tokens><token id=\"1\"><word>I</word><CharacterOffsetBegin>0</CharacterOffsetBegin><CharacterOffsetEnd>1</CharacterOffsetEnd><POS>PRP</POS><sentiment>Neutral</sentiment></token><token id=\"2\"><word>love</word><CharacterOffsetBegin>2</CharacterOffsetBegin><CharacterOffsetEnd>6</CharacterOffsetEnd><POS>VBP</POS><sentiment>Very positive</sentiment></token><token id=\"3\"><word>dogs</word><CharacterOffsetBegin>7</CharacterOffsetBegin><CharacterOffsetEnd>11</CharacterOffsetEnd><POS>NNS</POS><sentiment>Positive</sentiment></token><token id=\"4\"><word>.</word><CharacterOffsetBegin>11</CharacterOffsetBegin><CharacterOffsetEnd>12</CharacterOffsetEnd><POS>.</POS><sentiment>Neutral</sentiment></token></tokens><parse>(ROOT&#x0D;\n",
      "  (S&#x0D;\n",
      "    (NP (PRP I))&#x0D;\n",
      "    (VP (VBP love)&#x0D;\n",
      "      (NP (NNS dogs)))&#x0D;\n",
      "    (. .)))&#x0D;\n",
      "&#x0D;\n",
      "</parse><dependencies type=\"basic-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">love</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">love</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">love</governor><dependent idx=\"3\">dogs</dependent></dep><dep type=\"punct\"><governor idx=\"2\">love</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"collapsed-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">love</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">love</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">love</governor><dependent idx=\"3\">dogs</dependent></dep><dep type=\"punct\"><governor idx=\"2\">love</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"collapsed-ccprocessed-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">love</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">love</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">love</governor><dependent idx=\"3\">dogs</dependent></dep><dep type=\"punct\"><governor idx=\"2\">love</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"enhanced-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">love</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">love</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">love</governor><dependent idx=\"3\">dogs</dependent></dep><dep type=\"punct\"><governor idx=\"2\">love</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"enhanced-plus-plus-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">love</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">love</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">love</governor><dependent idx=\"3\">dogs</dependent></dep><dep type=\"punct\"><governor idx=\"2\">love</governor><dependent idx=\"4\">.</dependent></dep></dependencies></sentence></sentences></document></root>\n",
      "\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n",
      "<root><document><sentences><sentence id=\"1\" sentimentValue=\"1\" sentiment=\"Negative\"><tokens><token id=\"1\"><word>I</word><CharacterOffsetBegin>0</CharacterOffsetBegin><CharacterOffsetEnd>1</CharacterOffsetEnd><POS>PRP</POS><sentiment>Neutral</sentiment></token><token id=\"2\"><word>hate</word><CharacterOffsetBegin>2</CharacterOffsetBegin><CharacterOffsetEnd>6</CharacterOffsetEnd><POS>VBP</POS><sentiment>Very negative</sentiment></token><token id=\"3\"><word>puppies</word><CharacterOffsetBegin>7</CharacterOffsetBegin><CharacterOffsetEnd>14</CharacterOffsetEnd><POS>NNS</POS><sentiment>Neutral</sentiment></token><token id=\"4\"><word>.</word><CharacterOffsetBegin>14</CharacterOffsetBegin><CharacterOffsetEnd>15</CharacterOffsetEnd><POS>.</POS><sentiment>Neutral</sentiment></token></tokens><parse>(ROOT&#x0D;\n",
      "  (S&#x0D;\n",
      "    (NP (PRP I))&#x0D;\n",
      "    (VP (VBP hate)&#x0D;\n",
      "      (NP (NNS puppies)))&#x0D;\n",
      "    (. .)))&#x0D;\n",
      "&#x0D;\n",
      "</parse><dependencies type=\"basic-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">hate</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">hate</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">hate</governor><dependent idx=\"3\">puppies</dependent></dep><dep type=\"punct\"><governor idx=\"2\">hate</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"collapsed-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">hate</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">hate</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">hate</governor><dependent idx=\"3\">puppies</dependent></dep><dep type=\"punct\"><governor idx=\"2\">hate</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"collapsed-ccprocessed-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">hate</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">hate</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">hate</governor><dependent idx=\"3\">puppies</dependent></dep><dep type=\"punct\"><governor idx=\"2\">hate</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"enhanced-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">hate</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">hate</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">hate</governor><dependent idx=\"3\">puppies</dependent></dep><dep type=\"punct\"><governor idx=\"2\">hate</governor><dependent idx=\"4\">.</dependent></dep></dependencies><dependencies type=\"enhanced-plus-plus-dependencies\"><dep type=\"root\"><governor idx=\"0\">ROOT</governor><dependent idx=\"2\">hate</dependent></dep><dep type=\"nsubj\"><governor idx=\"2\">hate</governor><dependent idx=\"1\">I</dependent></dep><dep type=\"dobj\"><governor idx=\"2\">hate</governor><dependent idx=\"3\">puppies</dependent></dep><dep type=\"punct\"><governor idx=\"2\">hate</governor><dependent idx=\"4\">.</dependent></dep></dependencies></sentence></sentences></document></root>\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# make the twitter .csv as a .txt file and read all words from the file\n",
    "dep = dict() # dep is the list of results after dependency parsing\n",
    "pos = dict() # pos is the list of results after part-of-speech parsing\n",
    "sentiment = dict()\n",
    "print(\"Start preparing words...\")\n",
    "nlp = StanfordCoreNLP(r'C:\\Users\\sdzar\\Documents\\GitHub\\CNIT581-NLT\\data\\stanford-corenlp-full-2018-02-27',memory='8g')\n",
    "# this is the wiki corpus, you can change it to any other curpos you want\n",
    "f= open(\"./data/parsing_results.xml\",\"w+\")\n",
    "with open(\"./data/sentence.txt\", \"r\") as file:\n",
    "    # download CoreNLP 3.9.1 from https://stanfordnlp.github.io/CoreNLP/history.html\n",
    "    for i, line in enumerate(file):\n",
    "        if i == 2: break\n",
    "        props={'annotators': 'pos,depparse,sentiment','pipelineLanguage':'en','outputFormat':'xml'}\n",
    "        xml = nlp.annotate(line, properties=props)\n",
    "        print (xml)\n",
    "        f.write(xml)\n",
    "        #dep[i] = nlp.dependency_parse(line)\n",
    "        #pos[i] = nlp.pos_tag(line)\n",
    "        # sentiment[i] = nlp.annotate(line, properties=sentiment)\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(\"  --{}%  loaded.\".format(round(i/200*100, 2)))\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery.\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep in sentences 1: [('ROOT', 0, 2), ('nsubj', 2, 1), ('dobj', 2, 3), ('punct', 2, 4)]\n",
      "\n",
      "Pos in sentences 1: [('I', 'PRP'), ('love', 'VBP'), ('dogs', 'NNS'), ('.', '.')]\n",
      "\n",
      "Dep in sentences 2: [('ROOT', 0, 2), ('nsubj', 2, 1), ('dobj', 2, 3), ('punct', 2, 4)]\n",
      "\n",
      "Pos in sentences 2: [('I', 'PRP'), ('hate', 'VBP'), ('puppies', 'NNS'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examples of results\n",
    "for i in range(0,len(dep)):\n",
    "    print(\"Dep in sentences {}: {}\\n\".format(i+1,dep[i]))\n",
    "    print(\"Pos in sentences {}: {}\\n\".format(i+1,pos[i]))\n",
    "    # print(\"Sentiment of each sentence {}: {}\\n\".format(i+1,sentiment[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity between two words\n",
    "def similarity(w1,w2):\n",
    "    value = glove_model.similarity(w1,w2)\n",
    "    return [w1,w2,value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'love' and 'hate' is 0.6393098823113967\n",
      "Similarity between 'love' and 'have' is 0.5241775846462622\n",
      "Similarity between 'hate' and 'have' is 0.4914875401567831\n",
      "Similarity between 'dogs' and 'puppies' is 0.7978993201086827\n"
     ]
    }
   ],
   "source": [
    "# testing for word similarity\n",
    "list_test = []\n",
    "list_test.append(similarity(\"love\",\"hate\"))\n",
    "list_test.append(similarity(\"love\",\"have\"))\n",
    "list_test.append(similarity(\"hate\",\"have\"))\n",
    "list_test.append(similarity(\"dogs\",\"puppies\"))\n",
    "for i in list_test:\n",
    "    print(\"Similarity between '{}' and '{}' is {}\".format(i[0],i[1],i[2]))\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is for the CGT project(needs changes since pos is changed to dict())\n",
    "\n",
    "tags_noun = ['NN',\"NNP\",'NNS','NNPS']\n",
    "data_noun = find_words_pos(pos, tags_noun)\n",
    "tags_verb = ['VB',\"VBD\",'VBG','VBN', 'VBP','VBZ']\n",
    "data_verb = find_words_pos(pos, tags_verb)\n",
    "tags_JJRB = ['JJ',\"JJR\", 'JJS','RB','RBR','RBS']\n",
    "data_JJRB = find_words_pos(pos, tags_JJRB)\n",
    "# word = find_words(data, 'word')\n",
    "# tag = find_words(data, 'pos')\n",
    "print(\"Noun: \\n {}\".format(data_noun))\n",
    "print(\"Verb: \\n {}\".format(data_verb))\n",
    "print(\"Adjective & adverb: \\n {}\".format(data_JJRB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
